{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "plt.rcParams['figure.figsize'] = (5.0, 0.8) \n",
    "import matplotlib.patches as mpatches\n",
    "from util.color_util import *\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import torch.optim as optim\n",
    "import colorsys\n",
    "from model.RSA import *\n",
    "from model.WM18 import *\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from scipy import spatial\n",
    "from colormath.color_objects import sRGBColor, LabColor\n",
    "from colormath.color_conversions import convert_color\n",
    "from colormath.color_diff import delta_e_cie2000\n",
    "from skimage import io, color\n",
    "import random\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB = True\n",
    "EXTEND = True\n",
    "NUM_EPOCHE = 1000\n",
    "RETRAIN = False\n",
    "FOURIER_TRANSFORM = False\n",
    "SAMPLE_PER_COLOR = 3\n",
    "COLOR_DIM = 54 if FOURIER_TRANSFORM else 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load triples\n",
    "if EXTEND:\n",
    "    triple_train = pickle.load( open( \"../munroe/triple_train.p\", \"rb\" ) )\n",
    "    triple_dev = pickle.load( open( \"../munroe/triple_dev.p\", \"rb\" ) )\n",
    "    triple_test = pickle.load( open( \"../munroe/triple_test.p\", \"rb\" ) )\n",
    "else:\n",
    "    triple_train = pickle.load( open( \"../munroe/triple_train_reduce.p\", \"rb\" ) )\n",
    "    triple_dev = pickle.load( open( \"../munroe/triple_dev_reduce.p\", \"rb\" ) )\n",
    "    triple_test = pickle.load( open( \"../munroe/triple_test_reduce.p\", \"rb\" ) )\n",
    "    \n",
    "# load colors\n",
    "cdict_train_rgb = pickle.load( open( \"../munroe/cdict_train.p\", \"rb\" ) )\n",
    "cdict_dev_rgb = pickle.load( open( \"../munroe/cdict_dev.p\", \"rb\" ) )\n",
    "cdict_test_rgb = pickle.load( open( \"../munroe/cdict_test.p\", \"rb\" ) )\n",
    "\n",
    "cdict_train = dict()\n",
    "cdict_dev = dict()\n",
    "cdict_test = dict()\n",
    "\n",
    "if RGB:\n",
    "    cdict_train = cdict_train_rgb\n",
    "    cdict_dev = cdict_dev_rgb\n",
    "    cdict_test = cdict_test_rgb\n",
    "else:\n",
    "    for c in cdict_train_rgb.keys():\n",
    "        cdict_train[c] = torch.tensor(colors.rgb_to_hsv(cdict_train_rgb[c]))\n",
    "    for c in cdict_dev_rgb.keys():\n",
    "        cdict_dev[c] = torch.tensor(colors.rgb_to_hsv(cdict_dev_rgb[c]))\n",
    "    for c in cdict_test_rgb.keys():\n",
    "        cdict_test[c] = torch.tensor(colors.rgb_to_hsv(cdict_test_rgb[c]))\n",
    "\n",
    "# load embeddings for this dataset only\n",
    "embeddings = pickle.load( open( \"../munroe/glove_color.p\", \"rb\" ) )\n",
    "\n",
    "# generate test sets\n",
    "test_set = generate_test_set(triple_train, triple_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load literal speaker\n",
    "literal_s = WM18(color_dim=COLOR_DIM)\n",
    "checkpoint = torch.load(\"./save_model/\" + \"wm18_model\" + \".pth\")\n",
    "literal_s.load_state_dict(checkpoint['model'])\n",
    "# load literal listener\n",
    "literal_l = WM18(color_dim=COLOR_DIM)\n",
    "checkpoint = torch.load(\"./save_model/\" + \"literal_listener_wm18\" + \".pth\")\n",
    "literal_l.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18222"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(literal_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18222"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(literal_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict seen_pair set with 312 samples.\n",
      "predict unseen_pair set with 18 samples.\n",
      "predict unseen_base set with 62 samples.\n",
      "predict unseen_mod set with 41 samples.\n",
      "predict unseen_fully set with 17 samples.\n",
      "predict overall set with 450 samples.\n"
     ]
    }
   ],
   "source": [
    "net_predict = predict_color(literal_s, test_set, cdict_test, embeddings, sample_per_color=10, fourier=FOURIER_TRANSFORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 1 pragmatic where this is no listener involve\n",
    "pragmatic_predict_result = pragmatic_predict(net_predict, level=\"s1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition     cosine (std)    delta_E (std)\n",
      "------------  --------------  ---------------\n",
      "seen_pair     0.945 (0.135)   4.403 (3.158)\n",
      "unseen_pair   0.840 (0.355)   4.954 (2.431)\n",
      "unseen_base   0.793 (0.401)   8.814 (5.679)\n",
      "unseen_mod    0.595 (0.469)   11.602 (5.892)\n",
      "unseen_fully  0.527 (0.587)   13.777 (8.383)\n",
      "overall       0.872 (0.293)   6.020 (5.019)\n"
     ]
    }
   ],
   "source": [
    "evaluation_metrics = evaluate_color(net_predict, fmt=\"rgb\", reduced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition     cosine (std)    delta_E (std)\n",
      "------------  --------------  ---------------\n",
      "seen_pair     0.929 (0.137)   4.740 (3.024)\n",
      "unseen_pair   0.803 (0.363)   5.144 (2.382)\n",
      "unseen_base   0.782 (0.387)   9.094 (5.530)\n",
      "unseen_mod    0.592 (0.465)   11.775 (5.936)\n",
      "unseen_fully  0.525 (0.582)   13.885 (8.351)\n",
      "overall       0.858 (0.288)   6.320 (4.896)\n"
     ]
    }
   ],
   "source": [
    "evaluation_metrics = evaluate_color(net_predict, fmt=\"rgb\", reduced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition     cosine (std)    delta_E (std)\n",
      "------------  --------------  ---------------\n",
      "seen_pair     0.926 (0.157)   5.026 (3.216)\n",
      "unseen_pair   0.823 (0.388)   5.719 (2.773)\n",
      "unseen_base   0.751 (0.444)   10.101 (5.508)\n",
      "unseen_mod    0.603 (0.472)   13.187 (7.350)\n",
      "unseen_fully  0.552 (0.599)   15.025 (8.515)\n",
      "overall       0.855 (0.312)   6.882 (5.315)\n"
     ]
    }
   ],
   "source": [
    "evaluation_metrics = evaluate_color(pragmatic_predict_result, fmt=\"rgb\", eval_target=\"pred_delta_e_s1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pragmatic_predict(net_predict, literal_listener=None, level=\"s1\", lambda_pragmatic=0.1):\n",
    "    for set_name in net_predict.keys():\n",
    "        for triple in net_predict[set_name].keys():\n",
    "            sample_cos = []\n",
    "            sample_delta_e = []\n",
    "            index = 0\n",
    "            batch_emb1 = net_predict[set_name][triple][\"embeddings_1\"]\n",
    "            batch_emb2 = net_predict[set_name][triple][\"embeddings_2\"]\n",
    "            sample_base_cos = []\n",
    "            sample_base_delta_e = []\n",
    "            for sample in net_predict[set_name][triple][\"pred\"]:\n",
    "                pred_sample = sample.detach().numpy()\n",
    "                base = net_predict[set_name][triple][\"base\"].detach().numpy()[0]\n",
    "                # prob based on cosine\n",
    "                cos_dis = spatial.distance.cosine(pred_sample, base)\n",
    "                sample_cos.append(cos_dis)\n",
    "                # prob based on delta_e\n",
    "                c1 = sRGBColor(rgb_r=pred_sample[0], rgb_g=pred_sample[1], rgb_b=pred_sample[2])\n",
    "                c2 = sRGBColor(rgb_r=base[0], rgb_g=base[1], rgb_b=base[2])\n",
    "                # Convert from RGB to Lab Color Space\n",
    "                color1_lab = convert_color(c1, LabColor)\n",
    "                # Convert from RGB to Lab Color Space\n",
    "                color2_lab = convert_color(c2, LabColor)\n",
    "                delta_e = delta_e_cie2000(color1_lab, color2_lab)\n",
    "                sample_delta_e.append(delta_e)\n",
    "                \n",
    "                if level == \"s2\" and literal_listener is not None:\n",
    "                    emb1 = batch_emb1[index].unsqueeze(dim=0)\n",
    "                    emb2 = batch_emb2[index].unsqueeze(dim=0)\n",
    "                    base_pred = literal_listener(emb1, emb2, sample.unsqueeze(dim=0))[0]\n",
    "                    # prob pred_base based on the real base\n",
    "                    cos_sim = 1 - spatial.distance.cosine(base_pred.detach().numpy(), base)\n",
    "                    sample_base_cos.append(cos_sim)\n",
    "                    # prob based on delta_e\n",
    "                    c1_b = sRGBColor(rgb_r=base_pred[0], rgb_g=base_pred[1], rgb_b=base_pred[2])\n",
    "                    c2_b = sRGBColor(rgb_r=base[0], rgb_g=base[1], rgb_b=base[2])\n",
    "                    # Convert from RGB to Lab Color Space\n",
    "                    color1_lab_b = convert_color(c1_b, LabColor)\n",
    "                    # Convert from RGB to Lab Color Space\n",
    "                    color2_lab_b = convert_color(c2_b, LabColor)\n",
    "                    delta_e_b = delta_e_cie2000(color1_lab_b, color2_lab_b)\n",
    "                    sample_base_delta_e.append(delta_e_b)\n",
    "                index += 1\n",
    "\n",
    "            # s1 results\n",
    "            cos_prob = sample_cos\n",
    "            delta_e_prob = softmax_prob(sample_delta_e)\n",
    "            combine_prob = np.multiply(cos_prob, delta_e_prob)\n",
    "            cos_prob_n = np.argmax(cos_prob)\n",
    "            delta_e_prob_n = np.argmax(delta_e_prob)\n",
    "            combine_prob_n = np.argmax(combine_prob)\n",
    "            all_sample = net_predict[set_name][triple][\"pred\"]\n",
    "            net_predict[set_name][triple][\"pred_cos_s1\"] = \\\n",
    "                all_sample[cos_prob_n].unsqueeze(dim=0)\n",
    "            net_predict[set_name][triple][\"pred_delta_e_s1\"] = \\\n",
    "                all_sample[delta_e_prob_n].unsqueeze(dim=0)\n",
    "            net_predict[set_name][triple][\"pred_combine_s1\"] = \\\n",
    "                all_sample[combine_prob_n].unsqueeze(dim=0)\n",
    "#             pred_weight = None\n",
    "#             index = 0\n",
    "#             for prob in delta_e_prob:\n",
    "#                 if pred_weight is None:\n",
    "#                     pred_weight = prob * all_sample[index]\n",
    "#                 else:\n",
    "#                     pred_weight += prob * all_sample[index]\n",
    "#                 index += 1\n",
    "#             net_predict[set_name][triple][\"pred_weight_s1\"] = \\\n",
    "#                 pred_weight.unsqueeze(dim=0)\n",
    "\n",
    "            if level == \"s2\" and literal_listener is not None:\n",
    "                # s2 results\n",
    "                base_cos_prob = sample_base_cos\n",
    "                base_delta_e_prob = softmax_prob(sample_base_delta_e)\n",
    "                base_delta_e_prob = 1 - base_delta_e_prob\n",
    "                base_combine_prob = np.multiply(base_cos_prob, base_delta_e_prob)\n",
    "                base_cos_prob_n = np.argmax(base_cos_prob)\n",
    "                base_delta_e_prob_n = np.argmax(base_delta_e_prob)\n",
    "                base_combine_prob_n = np.argmax(base_combine_prob)\n",
    "                all_sample = net_predict[set_name][triple][\"pred\"]\n",
    "                net_predict[set_name][triple][\"base_pred_cos_l1\"] = \\\n",
    "                    all_sample[base_cos_prob_n].unsqueeze(dim=0)\n",
    "                net_predict[set_name][triple][\"base_pred_delta_e_l1\"] = \\\n",
    "                    all_sample[base_delta_e_prob_n].unsqueeze(dim=0)\n",
    "                net_predict[set_name][triple][\"base_pred_combine_l1\"] = \\\n",
    "                    all_sample[base_combine_prob_n].unsqueeze(dim=0)\n",
    "#                 base_pred_weight = None\n",
    "#                 index = 0\n",
    "#                 for prob in base_combine_prob:\n",
    "#                     if base_pred_weight is None:\n",
    "#                         base_pred_weight = prob * all_sample[index]\n",
    "#                     else:\n",
    "#                         base_pred_weight += prob * all_sample[index]\n",
    "#                     index += 1\n",
    "#                 net_predict[set_name][triple][\"base_pred_weight_l1\"] = \\\n",
    "#                     base_pred_weight.unsqueeze(dim=0)\n",
    "                base_pragmatic_prob = \\\n",
    "                    np.multiply((base_delta_e_prob ** lambda_pragmatic), \n",
    "                                (delta_e_prob ** (1 - lambda_pragmatic)))\n",
    "                base_pragmatic_prob_n = np.argmax(base_pragmatic_prob)\n",
    "                net_predict[set_name][triple][\"base_pred_pragmatic_s2\"] = \\\n",
    "                    all_sample[base_pragmatic_prob_n].unsqueeze(dim=0)\n",
    "            \n",
    "    return net_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 2 pragmatic where this is a listener involved\n",
    "# 0.7 for delta\n",
    "pragmatic_predict_result_lv2 = pragmatic_predict(net_predict, literal_listener=literal_l, level=\"s2\", lambda_pragmatic=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition     cosine (std)    delta_E (std)\n",
      "------------  --------------  ---------------\n",
      "seen_pair     0.929 (0.154)   4.980 (3.176)\n",
      "unseen_pair   0.834 (0.383)   5.786 (2.787)\n",
      "unseen_base   0.775 (0.411)   9.819 (5.437)\n",
      "unseen_mod    0.600 (0.484)   13.154 (7.435)\n",
      "unseen_fully  0.564 (0.586)   15.020 (8.538)\n",
      "overall       0.857 (0.311)   6.830 (5.315)\n"
     ]
    }
   ],
   "source": [
    "evaluation_metrics = evaluate_color(pragmatic_predict_result_lv2, fmt=\"rgb\", eval_target=\"base_pred_pragmatic_s2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_color_change_raw(source, direction, strength=1, save_path=None,\n",
    "                          fmt=\"rgb\"):\n",
    "    '''\n",
    "    compara: comparative color descriptions like `lighter`\n",
    "    source_str: source color like `blue`\n",
    "    strength: the ratio of exaggerating the effect to make it more perceivable\n",
    "    '''\n",
    "    ax = plt.gca()\n",
    "    N = 100\n",
    "    width, height = 1, 1\n",
    "    for x in np.linspace(0, width, N):\n",
    "        c = source+direction*x*strength\n",
    "        if fmt != \"rgb\":\n",
    "            c = colors.hsv_to_rgb(c)\n",
    "        ax.add_patch(mpatches.Rectangle([x,0],width/N,height,color=np.clip(c,0,1)))\n",
    "    print(c)\n",
    "    plt.axis('off')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('brown', ('more', 'mud'), ('brown',), 'mudbrown')\n",
      "ground truth\n",
      "tensor([0.4454, 0.3075, 0.1332])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAA5CAYAAABwBD0jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAABdUlEQVR4nO3WwU0DMRCG0QmihxRBRXTEhV5oiDtVMNwgIWvslQj5kd47WdrdjOMkn3Lo7gJIcXfrDQCcEiUgiigBUUQJiCJKQJT7ny4+PT68VdWxqqqr3usrYpfr3r4+fe58ffJcLz/Xg9kr696Yfb7e3sfJzD0zpu976Qwms/ec+dK9fbmPnZ/raH8LszfP43pnPv0uDb4Pv3Hmk9nnz63/Pr7tbzpvsL/5b2LHmT+/vB5qYPZP6Ti4d2s9u37N1zDbbLP/1+yhpZsA/oooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVEO3X3rPQB88k8JiCJKQBRRAqKIEhBFlIAoogRE+QCJ3pNIpgyAIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x57.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0\n",
      "tensor([0.6754, 0.2949, 0.2565])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAA5CAYAAABwBD0jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAB00lEQVR4nO3WzVGEMACG4cSxB4uwHE92ZEGerccqFg/uLBlNCKCj3+F5TshPCAHf2bosSwFIcfffEwBoiRIQRZSAKKIERBElIMr91sGX58f3UsrD9c9LKfVu3b4GbSmX+rm97ivlUnvnfjvn2/71Hkv3eOe62rl3/7rJ2PPrBnOuzVp012g+9vxZ+2NvjDt5F4P3NnnWL/feHHfPnM6+t2PPOvzW2jnv/l6PrNFo7NPfWhmu88/f23i9tr/RyXXt2LfjT69vtQzMfik9rJu1Pfe23Uyi2dc/d3Bds79Ojn/dXzv37l83G/t3rpuuUXfsg8+6Y87zd9F7b3vWf7330Wftzunsezv7rO3+k9/r/jUajX32W+vP59icjv9vbn+je+ZU+s89tOskgL8iSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkCUuizLf88B4MYvJSCKKAFRRAmIIkpAFFECoogSEOUDYnJ6hOAYRCAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x57.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7685936093330383\n",
      "13.679073115411521\n",
      "s2\n",
      "tensor([0.6944, 0.2637, 0.2456])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAA5CAYAAABwBD0jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAABwElEQVR4nO3WwXGCQBiG4cVJDxaRXnJPRykql3STKiQHo6zIAuIMfofnuWiQP7sivmPX930BSHF49QYAaqIERBElIIooAVFECYjyNvfi1+f7bynl+P/nqZTuHLG+nLohaKdyfn55LKWMX5+dq8+/ObZ1rqvmyvzccLyv5pbOfXJuYn+b52b3tnA9pq9dqc6dfV+r5hb29/Dc3dqPzQ3HZz639vu67PmBz3t6f6vmJtbZOtdce9Pc3fdx5fWo5j6+f7rSsPRL6Tg8vS5cutu5w+hx9PriXH386bnqwo7+X2t/5+etudbaW+ca52+aW9rbyv0tfm5b55av3e73SbX2XvfJ5P52vU9aa2+de/A+uR4fHWtadRLAXkQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiNL1ff/qPQBc+aUERBElIIooAVFECYgiSkAUUQKi/AFojYKGXyYslAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x57.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6895312666893005\n",
      "15.050404311524247\n"
     ]
    }
   ],
   "source": [
    "condition = \"unseen_fully\"\n",
    "triple_sample = random.choice(list(pragmatic_predict_result_lv2[condition].keys()))\n",
    "print(triple_sample)\n",
    "sample = pragmatic_predict_result_lv2[condition][triple_sample]\n",
    "plt.rcParams['figure.figsize'] = (5.0, 0.8) \n",
    "print(\"ground truth\")\n",
    "plot_color_change_raw(sample[\"base\"][0], sample[\"true\"][0] - sample[\"base\"][0], strength=1)\n",
    "print(\"s0\")\n",
    "plot_color_change_raw(sample[\"base\"][0], sample[\"pred\"][0] - sample[\"base\"][0], strength=2)\n",
    "\n",
    "cos_sim = 1 - spatial.distance.cosine(sample[\"true\"][0] - sample[\"base\"][0], sample[\"pred\"][0] - sample[\"base\"][0])\n",
    "print(cos_sim)\n",
    "c1_b = sRGBColor(rgb_r=sample[\"pred\"][0][0], rgb_g=sample[\"pred\"][0][1], rgb_b=sample[\"pred\"][0][2])\n",
    "c2_b = sRGBColor(rgb_r=sample[\"true\"][0][0], rgb_g=sample[\"true\"][0][1], rgb_b=sample[\"true\"][0][2])\n",
    "# Convert from RGB to Lab Color Space\n",
    "color1_lab_b = convert_color(c1_b, LabColor)\n",
    "# Convert from RGB to Lab Color Space\n",
    "color2_lab_b = convert_color(c2_b, LabColor)\n",
    "delta_e_b = delta_e_cie2000(color1_lab_b, color2_lab_b)\n",
    "print(delta_e_b)\n",
    "\n",
    "print(\"s2\")\n",
    "plot_color_change_raw(sample[\"base\"][0], sample[\"base_pred_pragmatic_s2\"][0] - sample[\"base\"][0], strength=2)\n",
    "\n",
    "cos_sim = 1 - spatial.distance.cosine(sample[\"true\"][0] - sample[\"base\"][0], sample[\"base_pred_pragmatic_s2\"][0] - sample[\"base\"][0])\n",
    "print(cos_sim)\n",
    "c1_b = sRGBColor(rgb_r=sample[\"base_pred_pragmatic_s2\"][0][0], rgb_g=sample[\"base_pred_pragmatic_s2\"][0][1], rgb_b=sample[\"base_pred_pragmatic_s2\"][0][2])\n",
    "c2_b = sRGBColor(rgb_r=sample[\"true\"][0][0], rgb_g=sample[\"true\"][0][1], rgb_b=sample[\"true\"][0][2])\n",
    "# Convert from RGB to Lab Color Space\n",
    "color1_lab_b = convert_color(c1_b, LabColor)\n",
    "# Convert from RGB to Lab Color Space\n",
    "color2_lab_b = convert_color(c2_b, LabColor)\n",
    "delta_e_b = delta_e_cie2000(color1_lab_b, color2_lab_b)\n",
    "print(delta_e_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6754, 0.2949, 0.2565])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAA5CAYAAABwBD0jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAB00lEQVR4nO3WzVGEMACG4cSxB4uwHE92ZEGerccqFg/uLBlNCKCj3+F5TshPCAHf2bosSwFIcfffEwBoiRIQRZSAKKIERBElIMr91sGX58f3UsrD9c9LKfVu3b4GbSmX+rm97ivlUnvnfjvn2/71Hkv3eOe62rl3/7rJ2PPrBnOuzVp012g+9vxZ+2NvjDt5F4P3NnnWL/feHHfPnM6+t2PPOvzW2jnv/l6PrNFo7NPfWhmu88/f23i9tr/RyXXt2LfjT69vtQzMfik9rJu1Pfe23Uyi2dc/d3Bds79Ojn/dXzv37l83G/t3rpuuUXfsg8+6Y87zd9F7b3vWf7330Wftzunsezv7rO3+k9/r/jUajX32W+vP59icjv9vbn+je+ZU+s89tOskgL8iSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkAUUQKiiBIQRZSAKKIERBElIIooAVFECYgiSkCUuizLf88B4MYvJSCKKAFRRAmIIkpAFFECoogSEOUDYnJ6hOAYRCAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x57.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6944, 0.2637, 0.2456])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAA5CAYAAABwBD0jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAABwElEQVR4nO3WwXGCQBiG4cVJDxaRXnJPRykql3STKiQHo6zIAuIMfofnuWiQP7sivmPX930BSHF49QYAaqIERBElIIooAVFECYjyNvfi1+f7bynl+P/nqZTuHLG+nLohaKdyfn55LKWMX5+dq8+/ObZ1rqvmyvzccLyv5pbOfXJuYn+b52b3tnA9pq9dqc6dfV+r5hb29/Dc3dqPzQ3HZz639vu67PmBz3t6f6vmJtbZOtdce9Pc3fdx5fWo5j6+f7rSsPRL6Tg8vS5cutu5w+hx9PriXH386bnqwo7+X2t/5+etudbaW+ca52+aW9rbyv0tfm5b55av3e73SbX2XvfJ5P52vU9aa2+de/A+uR4fHWtadRLAXkQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiNL1ff/qPQBc+aUERBElIIooAVFECYgiSkAUUQKi/AFojYKGXyYslAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x57.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_color_change_raw(sample[\"base\"][0], sample[\"pred\"][0] - sample[\"base\"][0], strength=2)\n",
    "plot_color_change_raw(sample[\"base\"][0], sample[\"base_pred_pragmatic_s2\"][0] - sample[\"base\"][0], strength=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6017, 0.3197, 0.2113],\n",
       "        [0.6400, 0.3218, 0.2087],\n",
       "        [0.6269, 0.3268, 0.2083],\n",
       "        [0.6112, 0.3041, 0.2059],\n",
       "        [0.6581, 0.3366, 0.2216],\n",
       "        [0.5915, 0.3032, 0.1990],\n",
       "        [0.5998, 0.3100, 0.2153],\n",
       "        [0.6378, 0.3322, 0.2285],\n",
       "        [0.6101, 0.3226, 0.2035],\n",
       "        [0.6238, 0.3353, 0.2206]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5280, 0.3446, 0.1662])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"base\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4454, 0.3075, 0.1332])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"true\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
