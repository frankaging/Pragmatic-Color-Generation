{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "plt.rcParams['figure.figsize'] = (5.0, 0.8) \n",
    "import matplotlib.patches as mpatches\n",
    "from util.color_util import *\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import torch.optim as optim\n",
    "import colorsys\n",
    "from model.RSA import *\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from scipy import spatial\n",
    "from colormath.color_objects import sRGBColor, LabColor\n",
    "from colormath.color_conversions import convert_color\n",
    "from colormath.color_diff import delta_e_cie2000\n",
    "from skimage import io, color\n",
    "import random\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB = True\n",
    "EXTEND = True\n",
    "NUM_EPOCHE = 1000\n",
    "RETRAIN = False\n",
    "FOURIER_TRANSFORM = False\n",
    "MODEL_NAME = \"literal_speaker\"\n",
    "SAMPLE_PER_COLOR = 3\n",
    "COLOR_DIM = 54 if FOURIER_TRANSFORM else 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load triples\n",
    "if EXTEND:\n",
    "    triple_train = pickle.load( open( \"../munroe/triple_train.p\", \"rb\" ) )\n",
    "    triple_dev = pickle.load( open( \"../munroe/triple_dev.p\", \"rb\" ) )\n",
    "    triple_test = pickle.load( open( \"../munroe/triple_test.p\", \"rb\" ) )\n",
    "else:\n",
    "    triple_train = pickle.load( open( \"../munroe/triple_train_reduce.p\", \"rb\" ) )\n",
    "    triple_dev = pickle.load( open( \"../munroe/triple_dev_reduce.p\", \"rb\" ) )\n",
    "    triple_test = pickle.load( open( \"../munroe/triple_test_reduce.p\", \"rb\" ) )\n",
    "    \n",
    "# load colors\n",
    "cdict_train_rgb = pickle.load( open( \"../munroe/cdict_train.p\", \"rb\" ) )\n",
    "cdict_dev_rgb = pickle.load( open( \"../munroe/cdict_dev.p\", \"rb\" ) )\n",
    "cdict_test_rgb = pickle.load( open( \"../munroe/cdict_test.p\", \"rb\" ) )\n",
    "\n",
    "cdict_train = dict()\n",
    "cdict_dev = dict()\n",
    "cdict_test = dict()\n",
    "\n",
    "if RGB:\n",
    "    cdict_train = cdict_train_rgb\n",
    "    cdict_dev = cdict_dev_rgb\n",
    "    cdict_test = cdict_test_rgb\n",
    "else:\n",
    "    for c in cdict_train_rgb.keys():\n",
    "        cdict_train[c] = torch.tensor(colors.rgb_to_hsv(cdict_train_rgb[c]))\n",
    "    for c in cdict_dev_rgb.keys():\n",
    "        cdict_dev[c] = torch.tensor(colors.rgb_to_hsv(cdict_dev_rgb[c]))\n",
    "    for c in cdict_test_rgb.keys():\n",
    "        cdict_test[c] = torch.tensor(colors.rgb_to_hsv(cdict_test_rgb[c]))\n",
    "\n",
    "# load embeddings for this dataset only\n",
    "embeddings = pickle.load( open( \"../munroe/glove_color.p\", \"rb\" ) )\n",
    "\n",
    "# generate test sets\n",
    "test_set = generate_test_set(triple_train, triple_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = nn.MSELoss(reduction = 'none')\n",
    "cos = nn.CosineSimilarity(dim=1)\n",
    "colorLoss = lambda source, target, wg: ((1-cos(wg, target-source)) + mse(target, source+wg).sum(dim=-1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LiteralSpeaker(color_dim=COLOR_DIM)\n",
    "if RETRAIN:\n",
    "    '''\n",
    "    Skip this as you dont have to retrain!\n",
    "    Main training loop\n",
    "    '''\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    debug = False\n",
    "    sample_per_color = SAMPLE_PER_COLOR\n",
    "\n",
    "    for i in range(NUM_EPOCHE):\n",
    "        net.train()\n",
    "        loss = 0.0\n",
    "        batch_num = 0\n",
    "        batch_index = 0\n",
    "        for batch_emb1, batch_emb2, batch_base_color, batch_base_color_raw, batch_target_color in \\\n",
    "            generate_batch(cdict_train, triple_train, embeddings,\n",
    "                           sample_per_color=sample_per_color,\n",
    "                           fourier=FOURIER_TRANSFORM):\n",
    "            pred = net(batch_emb1, batch_emb2, batch_base_color)\n",
    "            wg = pred - batch_base_color_raw           # calculate the wg for the loss to use\n",
    "            batch_loss = colorLoss(batch_base_color_raw, batch_target_color, wg)\n",
    "            loss += batch_loss\n",
    "            batch_num += batch_emb1.shape[0]           # sum up total sample size\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if debug:\n",
    "                print(f\"Batch: {batch_index+1}, train loss:{batch_loss.detach().numpy()}\")\n",
    "            batch_index += 1\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoche: {i+1}, train loss:{loss.detach().numpy()}\")\n",
    "    # save the literal speaker to disk\n",
    "    checkpoint = {\"model\" : net.state_dict(), \"name\" : MODEL_NAME}\n",
    "    torch.save(checkpoint, \"./save_model/\" + MODEL_NAME + \".pth\")\n",
    "else:\n",
    "    checkpoint = torch.load(\"./save_model/\" + MODEL_NAME + \".pth\")\n",
    "    net.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dev_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-690bd7189a82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdict_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_per_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfourier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFOURIER_TRANSFORM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dev_set' is not defined"
     ]
    }
   ],
   "source": [
    "net_predict = predict_color(net, test_set, cdict_test, embeddings, sample_per_color=1, fourier=FOURIER_TRANSFORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition     cosine (std)    delta_E (std)\n",
      "------------  --------------  ---------------\n",
      "seen_pair     0.949 (0.129)   3.766 (2.712)\n",
      "unseen_pair   0.760 (0.420)   6.319 (3.038)\n",
      "unseen_base   0.786 (0.326)   8.583 (5.048)\n",
      "unseen_mod    0.426 (0.536)   11.965 (5.618)\n",
      "unseen_fully  0.351 (0.587)   14.055 (6.626)\n",
      "overall       0.848 (0.325)   5.668 (4.846)\n"
     ]
    }
   ],
   "source": [
    "evaluation_metrics = evaluate_color(net_predict, fmt=\"rgb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
