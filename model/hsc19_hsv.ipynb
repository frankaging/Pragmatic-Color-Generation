{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This serves as the purpose to reproduce what Han et al. had done in hsv based model.\n",
    "https://arxiv.org/pdf/1909.07586.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "plt.rcParams['figure.figsize'] = (5.0, 0.8) \n",
    "import matplotlib.patches as mpatches\n",
    "from util.color_util import *\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import torch.optim as optim\n",
    "import colorsys\n",
    "from model.HSC19 import *\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from scipy import spatial\n",
    "from colormath.color_objects import sRGBColor, LabColor\n",
    "from colormath.color_conversions import convert_color\n",
    "from colormath.color_diff import delta_e_cie2000\n",
    "from skimage import io, color\n",
    "import random\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB = False\n",
    "EXTEND = True\n",
    "\n",
    "# load triples\n",
    "if EXTEND:\n",
    "    triple_train = pickle.load( open( \"../munroe/triple_train.p\", \"rb\" ) )\n",
    "    triple_dev = pickle.load( open( \"../munroe/triple_dev.p\", \"rb\" ) )\n",
    "    triple_test = pickle.load( open( \"../munroe/triple_test.p\", \"rb\" ) )\n",
    "else:\n",
    "    triple_train = pickle.load( open( \"../munroe/triple_train_reduce.p\", \"rb\" ) )\n",
    "    triple_dev = pickle.load( open( \"../munroe/triple_dev_reduce.p\", \"rb\" ) )\n",
    "    triple_test = pickle.load( open( \"../munroe/triple_test_reduce.p\", \"rb\" ) )\n",
    "\n",
    "# load colors\n",
    "cdict_train_rgb = pickle.load( open( \"../munroe/cdict_train.p\", \"rb\" ) )\n",
    "cdict_dev_rgb = pickle.load( open( \"../munroe/cdict_dev.p\", \"rb\" ) )\n",
    "cdict_test_rgb = pickle.load( open( \"../munroe/cdict_test.p\", \"rb\" ) )\n",
    "\n",
    "cdict_train = dict()\n",
    "cdict_dev = dict()\n",
    "cdict_test = dict()\n",
    "\n",
    "if RGB:\n",
    "    cdict_train = cdict_train_rgb\n",
    "    cdict_dev = cdict_dev_rgb\n",
    "    cdict_test = cdict_test_rgb\n",
    "else:\n",
    "    for c in cdict_train_rgb.keys():\n",
    "        cdict_train[c] = torch.tensor(colors.rgb_to_hsv(cdict_train_rgb[c]))\n",
    "    for c in cdict_dev_rgb.keys():\n",
    "        cdict_dev[c] = torch.tensor(colors.rgb_to_hsv(cdict_dev_rgb[c]))\n",
    "    for c in cdict_test_rgb.keys():\n",
    "        cdict_test[c] = torch.tensor(colors.rgb_to_hsv(cdict_test_rgb[c]))\n",
    "\n",
    "# load embeddings for this dataset only\n",
    "embeddings = pickle.load( open( \"../munroe/glove_color.p\", \"rb\" ) )\n",
    "\n",
    "# generate test sets\n",
    "test_set = generate_test_set(triple_train, triple_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = nn.MSELoss(reduction = 'none')\n",
    "colorLoss = lambda h, sv, target: ((1. - torch.cos((h.squeeze(dim=-1) - target[:,0])*2*np.pi)) + \\\n",
    "                                   mse(target[:,1:], sv).sum(dim=-1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HSC19_HSV(color_dim=3)\n",
    "NUM_EPOCHE = 1000\n",
    "RETRAIN = False\n",
    "FOURIER_TRANSFORM = False\n",
    "MODEL_NAME = \"hsc19_hsv\"\n",
    "\n",
    "if RETRAIN:\n",
    "    '''\n",
    "    Skip this as you dont have to retrain!\n",
    "    Main training loop\n",
    "    '''\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    debug = False\n",
    "    sample_per_color = 1                               # Set to 1 to be as the same as the original paper\n",
    "\n",
    "    for i in range(NUM_EPOCHE):\n",
    "        net.train()\n",
    "        loss = 0.0\n",
    "        batch_num = 0\n",
    "        batch_index = 0\n",
    "        for batch_emb1, batch_emb2, batch_base_color, batch_base_color_raw, batch_target_color in \\\n",
    "            generate_batch(cdict_train, triple_train, embeddings,\n",
    "                           sample_per_color=sample_per_color,\n",
    "                           fourier=False):\n",
    "            h_pred, sv_pred = net(batch_emb1, batch_emb2, batch_base_color)\n",
    "            batch_loss = colorLoss(h_pred, sv_pred, batch_target_color)\n",
    "            loss += batch_loss\n",
    "            batch_num += batch_emb1.shape[0]           # sum up total sample size\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if debug:\n",
    "                print(f\"Batch: {batch_index+1}, train loss:{batch_loss.detach().numpy()}\")\n",
    "            batch_index += 1\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoche: {i+1}, train loss:{loss.detach().numpy()}\")\n",
    "    # save the literal speaker to disk\n",
    "    checkpoint = {\"model\" : net.state_dict(), \"name\" : MODEL_NAME}\n",
    "    torch.save(checkpoint, \"./save_model/\" + MODEL_NAME + \".pth\")\n",
    "else:\n",
    "    checkpoint = torch.load(\"./save_model/\" + MODEL_NAME + \".pth\")\n",
    "    net.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20011"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict seen_pair set with 312 samples.\n",
      "predict unseen_pair set with 18 samples.\n",
      "predict unseen_base set with 62 samples.\n",
      "predict unseen_mod set with 41 samples.\n",
      "predict unseen_fully set with 17 samples.\n",
      "predict overall set with 450 samples.\n"
     ]
    }
   ],
   "source": [
    "net_predict = predict_color_hsv(net, test_set, cdict_test, embeddings, sample_per_color=5, fourier=FOURIER_TRANSFORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition     cosine (std)    delta_E (std)\n",
      "------------  --------------  ---------------\n",
      "seen_pair     0.869 (0.270)   5.582 (5.003)\n",
      "unseen_pair   0.739 (0.415)   7.997 (5.310)\n",
      "unseen_base   0.424 (0.511)   20.468 (12.904)\n",
      "unseen_mod    0.620 (0.425)   15.962 (12.736)\n",
      "unseen_fully  0.408 (0.554)   16.428 (9.018)\n",
      "overall       0.758 (0.418)   8.959 (9.643)\n"
     ]
    }
   ],
   "source": [
    "evaluation_metrics = evaluate_color(net_predict, fmt=\"hsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
