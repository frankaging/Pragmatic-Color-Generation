{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This serves as the purpose to reproduce what Han et al. had done in rgb based model.\n",
    "https://arxiv.org/pdf/1909.07586.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "plt.rcParams['figure.figsize'] = (5.0, 0.8) \n",
    "import matplotlib.patches as mpatches\n",
    "from util.color_util import *\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import torch.optim as optim\n",
    "import colorsys\n",
    "from model.HSC19 import *\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from scipy import spatial\n",
    "from colormath.color_objects import sRGBColor, LabColor\n",
    "from colormath.color_conversions import convert_color\n",
    "from colormath.color_diff import delta_e_cie2000\n",
    "from skimage import io, color\n",
    "import random\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB = True\n",
    "EXTEND = True\n",
    "\n",
    "# load triples\n",
    "if EXTEND:\n",
    "    triple_train = pickle.load( open( \"../munroe/triple_train.p\", \"rb\" ) )\n",
    "    triple_dev = pickle.load( open( \"../munroe/triple_dev.p\", \"rb\" ) )\n",
    "    triple_test = pickle.load( open( \"../munroe/triple_test.p\", \"rb\" ) )\n",
    "else:\n",
    "    triple_train = pickle.load( open( \"../munroe/triple_train_reduce.p\", \"rb\" ) )\n",
    "    triple_dev = pickle.load( open( \"../munroe/triple_dev_reduce.p\", \"rb\" ) )\n",
    "    triple_test = pickle.load( open( \"../munroe/triple_test_reduce.p\", \"rb\" ) )\n",
    "    \n",
    "# load colors\n",
    "cdict_train_rgb = pickle.load( open( \"../munroe/cdict_train.p\", \"rb\" ) )\n",
    "cdict_dev_rgb = pickle.load( open( \"../munroe/cdict_dev.p\", \"rb\" ) )\n",
    "cdict_test_rgb = pickle.load( open( \"../munroe/cdict_test.p\", \"rb\" ) )\n",
    "\n",
    "cdict_train = dict()\n",
    "cdict_dev = dict()\n",
    "cdict_test = dict()\n",
    "\n",
    "if RGB:\n",
    "    cdict_train = cdict_train_rgb\n",
    "    cdict_dev = cdict_dev_rgb\n",
    "    cdict_test = cdict_test_rgb\n",
    "else:\n",
    "    for c in cdict_train_rgb.keys():\n",
    "        cdict_train[c] = torch.tensor(colors.rgb_to_hsv(cdict_train_rgb[c]))\n",
    "    for c in cdict_dev_rgb.keys():\n",
    "        cdict_dev[c] = torch.tensor(colors.rgb_to_hsv(cdict_dev_rgb[c]))\n",
    "    for c in cdict_test_rgb.keys():\n",
    "        cdict_test[c] = torch.tensor(colors.rgb_to_hsv(cdict_test_rgb[c]))\n",
    "\n",
    "# load embeddings for this dataset only\n",
    "embeddings = pickle.load( open( \"../munroe/glove_color.p\", \"rb\" ) )\n",
    "\n",
    "# generate test sets\n",
    "test_set = generate_test_set(triple_train, triple_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = nn.MSELoss(reduction = 'none')\n",
    "cos = nn.CosineSimilarity(dim=1)\n",
    "colorLoss = lambda source, target, wg: ((1-cos(wg, target-source)) + mse(target, source+wg).sum(dim=-1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HSC19_RGB(color_dim=3)\n",
    "NUM_EPOCHE = 1000\n",
    "RETRAIN = False\n",
    "FOURIER_TRANSFORM = False\n",
    "MODEL_NAME = \"hsc19_rgb\"\n",
    "\n",
    "if RETRAIN:\n",
    "    '''\n",
    "    Skip this as you dont have to retrain!\n",
    "    Main training loop\n",
    "    '''\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    debug = False\n",
    "    sample_per_color = 1                               # Set to 1 to be as the same as the original paper\n",
    "\n",
    "    for i in range(NUM_EPOCHE):\n",
    "        net.train()\n",
    "        loss = 0.0\n",
    "        batch_num = 0\n",
    "        batch_index = 0\n",
    "        for batch_emb1, batch_emb2, batch_base_color, batch_base_color_raw, batch_target_color in \\\n",
    "            generate_batch(cdict_train, triple_train, embeddings,\n",
    "                           sample_per_color=sample_per_color,\n",
    "                           fourier=False):\n",
    "            pred = net(batch_emb1, batch_emb2, batch_base_color)\n",
    "            wg = pred - batch_base_color_raw           # calculate the wg for the loss to use\n",
    "            batch_loss = colorLoss(batch_base_color_raw, batch_target_color, wg)\n",
    "            loss += batch_loss\n",
    "            batch_num += batch_emb1.shape[0]           # sum up total sample size\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            if debug:\n",
    "                print(f\"Batch: {batch_index+1}, train loss:{batch_loss.detach().numpy()}\")\n",
    "            batch_index += 1\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoche: {i+1}, train loss:{loss.detach().numpy()}\")\n",
    "    # save the literal speaker to disk\n",
    "    checkpoint = {\"model\" : net.state_dict(), \"name\" : MODEL_NAME}\n",
    "    torch.save(checkpoint, \"./save_model/\" + MODEL_NAME + \".pth\")\n",
    "else:\n",
    "    checkpoint = torch.load(\"./save_model/\" + MODEL_NAME + \".pth\")\n",
    "    net.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict seen_pair set with 312 samples.\n",
      "predict unseen_pair set with 18 samples.\n",
      "predict unseen_base set with 62 samples.\n",
      "predict unseen_mod set with 41 samples.\n",
      "predict unseen_fully set with 17 samples.\n",
      "predict overall set with 450 samples.\n"
     ]
    }
   ],
   "source": [
    "net_predict = predict_color(net, test_set, cdict_test, embeddings, sample_per_color=5, fourier=FOURIER_TRANSFORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition     cosine (std)    delta_E (std)\n",
      "------------  --------------  ---------------\n",
      "seen_pair     0.881 (0.163)   5.358 (2.815)\n",
      "unseen_pair   0.626 (0.512)   6.782 (2.502)\n",
      "unseen_base   0.689 (0.478)   9.657 (6.201)\n",
      "unseen_mod    0.382 (0.424)   13.402 (4.694)\n",
      "unseen_fully  0.252 (0.586)   13.029 (6.174)\n",
      "overall       0.771 (0.350)   7.073 (4.776)\n"
     ]
    }
   ],
   "source": [
    "evaluation_metrics = evaluate_color(net_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
